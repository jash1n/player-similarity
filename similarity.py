import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from PIL import Image
import numpy as np
import unicodedata


# =====================
# ãƒšãƒ¼ã‚¸è¨­å®š
# =====================
st.set_page_config(
    page_title="é¸æ‰‹é¡ä¼¼åº¦çµ±åˆã‚·ã‚¹ãƒ†ãƒ ",
    layout="wide"
)

st.title("é¸æ‰‹ç™ºæ˜ã‚·ã‚¹ãƒ†ãƒ ï¼ˆTF-IDF Ã— ã‚¹ã‚¿ãƒƒãƒ„ Ã— ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼‰")

# =====================
# CSV ãƒ‘ã‚¹
# =====================
TFIDF_CSV = "data/ç‰¹å¾´èªãƒãƒˆãƒªãƒƒã‚¯ã‚¹.csv"
STATS_CSV = "data/ã‚¹ã‚¿ãƒƒãƒ„ãƒãƒˆãƒªãƒƒã‚¯ã‚¹.csv"
HEATMAP_CSV = "data/ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒãƒˆãƒªãƒƒã‚¯ã‚¹.csv"
HEATMAP_IMG_DIR = Path("data/ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")

# =====================
# é–¢æ•°
# =====================
@st.cache_data
def load_matrix(path):
    df = pd.read_csv(path, index_col=0, encoding="utf-8-sig")
    df.index = df.index.astype(str)
    df.columns = df.columns.astype(str)
    return df

def minmax_normalize(df):
    min_val = df.min().min()
    max_val = df.max().max()
    if max_val - min_val == 0:
        return df * 0
    return (df - min_val) / (max_val - min_val)

@st.cache_data
def load_youtube_links(path="data/youtube_link.csv"):
    df = pd.read_csv(path)
    return dict(zip(df["Player"], df["Link"]))

youtube_links = load_youtube_links()

def show_youtube(player_name):
    link = youtube_links.get(player_name)
    if link:
        st.video(link)
    else:
        st.info(f"YouTubeå‹•ç”»ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“: {player_name}")

def normalize_name(name):
    return unicodedata.normalize("NFC", name)

def normalize_name(name):
    return unicodedata.normalize("NFC", name)


# =====================
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# =====================
try:
    tfidf = load_matrix(TFIDF_CSV)
    stats = load_matrix(STATS_CSV)
    heatmap = load_matrix(HEATMAP_CSV)
except Exception as e:
    st.error(f"CSVèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()



# =====================
# ç©ºç™½ãƒ»æ”¹è¡Œã‚’å‰Šé™¤ã—ã¦æ­£è¦åŒ–
# =====================
for df in [tfidf, stats, heatmap]:
    df.index = df.index.str.strip()
    df.columns = df.columns.str.strip()

for df in [tfidf, stats, heatmap]:
    df.index = df.index.map(normalize_name)
    df.columns = df.columns.map(normalize_name)


# =====================
# ä¸è¦é¸æ‰‹ã‚’å‰Šé™¤ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã«å­˜åœ¨ã—ã¦ã¯ã„ã‘ãªã„é¸æ‰‹ï¼‰
# =====================
remove_players = ['Ben Mee', 'Ethan Pinnock']
heatmap = heatmap.drop(remove_players, axis=0, errors='ignore')
heatmap = heatmap.drop(remove_players, axis=1, errors='ignore')

# =====================
# å›½å†…ãƒ»æµ·å¤–é¸æ‰‹ãƒªã‚¹ãƒˆã‚’ TF-IDF åŸºæº–ã§ä½œæˆ
# =====================
domestic_players = sorted(tfidf.index)
overseas_players = sorted(tfidf.columns)

# =====================
# heatmap ã«å­˜åœ¨ã—ãªã„é¸æ‰‹ã‚’ 0 ã§åŸ‹ã‚ã‚‹
# =====================
heatmap = heatmap.reindex(index=domestic_players, columns=overseas_players, fill_value=0)

# stats ã‚‚å¿µã®ãŸã‚åŒæ§˜ã«è£œå®Œ
stats = stats.reindex(index=domestic_players, columns=overseas_players, fill_value=0)

# =====================
# TF-IDF ãƒãƒˆãƒªã‚¯ã‚¹ã¯å…ƒã®ã¾ã¾
# =====================
tfidf = tfidf.reindex(index=domestic_players, columns=overseas_players, fill_value=0)

# =====================
# æ­£è¦åŒ–
# =====================
tfidf_n = minmax_normalize(tfidf)
stats_n = minmax_normalize(stats)
heatmap_n = minmax_normalize(heatmap)

# =====================
# é‡ã¿è¨­å®š
# =====================
st.sidebar.header("âš– é‡ã¿è¨­å®š")
w_tfidf = st.sidebar.slider("TF-IDF", 0.0, 1.0, 1.0, 0.01)
w_stats = st.sidebar.slider("ã‚¹ã‚¿ãƒƒãƒ„", 0.0, 1.0, 1.0, 0.01)
w_heat = st.sidebar.slider("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", 0.0, 1.0, 1.0, 0.01)

total = w_tfidf + w_stats + w_heat
w_tfidf /= total
w_stats /= total
w_heat /= total

# =====================
# çµ±åˆé¡ä¼¼åº¦
# =====================
final_similarity = (
    tfidf_n * w_tfidf +
    stats_n * w_stats +
    heatmap_n * w_heat
)

# =====================
# æ¤œç´¢æ–¹å‘ã‚¹ã‚¤ãƒƒãƒ
# =====================
st.sidebar.header("ğŸ” æ¤œç´¢æ–¹å‘")
mode = st.sidebar.radio(
    "æ¤œç´¢æ–¹å‘ã‚’é¸æŠ",
    ["å›½å†… â†’ æµ·å¤–", "æµ·å¤– â†’ å›½å†…"]
)

# =====================
# é¡ä¼¼é¸æ‰‹æ¤œç´¢
# =====================
st.subheader("é¡ä¼¼é¸æ‰‹æ¤œç´¢")
TOP_N = 7

if mode == "å›½å†… â†’ æµ·å¤–":
    base_players = domestic_players[::-1]
    sim_matrix = final_similarity
    base_label = "å›½å†…é¸æ‰‹"
    target_label = "æµ·å¤–é¸æ‰‹"
else:
    base_players = overseas_players
    sim_matrix = final_similarity.T
    base_label = "æµ·å¤–é¸æ‰‹"
    target_label = "å›½å†…é¸æ‰‹"

player = st.selectbox(f"{base_label}ã‚’é¸æŠ", base_players)

result = (
    sim_matrix.loc[player]
    .sort_values(ascending=False)
    .head(TOP_N)
    .reset_index()
)

result.columns = [target_label, "é¡ä¼¼åº¦"]
result["é¡ä¼¼åº¦"] = result["é¡ä¼¼åº¦"].round(3)

st.dataframe(
    result,
    width=700,
    height=280,
    hide_index=True
)

with st.expander("ğŸ¥ é¸æ‰‹ãƒã‚¤ãƒ©ã‚¤ãƒˆå‹•ç”»"):
    st.markdown(f"### ğŸ¯ é¸æŠé¸æ‰‹ï¼š{player}")
    show_youtube(player)

    st.markdown("### ğŸ” é¡ä¼¼é¸æ‰‹")
    cols = st.columns(2)
    for i, p in enumerate(result[target_label]):
        with cols[i % 2]:
            st.markdown(f"**{p}**")
            show_youtube(p)

# =====================
# é¸æ‰‹ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆç”»åƒè¡¨ç¤ºï¼‰
# =====================
with st.expander("ğŸ—º é¸æ‰‹ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆé¸æŠï¼‹é¡ä¼¼é¸æ‰‹ï¼‰"):
    st.markdown(f"### ğŸ¯ é¸æŠé¸æ‰‹ï¼š{player}")
    base_img = HEATMAP_IMG_DIR / f"{normalize_name(player)}.png"
    if base_img.exists():
        st.image(base_img, width=350)
    else:
        st.warning(f"ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {player}")

    st.markdown("### ğŸ” é¡ä¼¼é¸æ‰‹")
    cols = st.columns(4)
    for i, p in enumerate(result[target_label]):
        img_path = HEATMAP_IMG_DIR / f"{normalize_name(p)}.png"
        with cols[i % 4]:
            if img_path.exists():
                st.image(img_path, caption=p, width=250)
            else:
                st.warning(p)

# =====================
# çµ±åˆé¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹è¡¨ç¤º
# =====================
with st.expander("ğŸ“Š çµ±åˆé¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ã‚’è¦‹ã‚‹"):
    st.dataframe(
        final_similarity,
        height=600
    )

